{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-f41ba763a664>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-f41ba763a664>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    from tensorflow.python.\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use tensorflow goujian shendu xuexi moxing\n",
    "\n",
    "#dingyile yigeceng()\n",
    "def model(inputs):\n",
    "    #goujianle quanlianjieceng\n",
    "    #tf.layers.Dense(100,activation=tf.nn.relu)\n",
    "    #tf.layers.Dense(100,activation=tf.nn.sigmoid)\n",
    "    #return outputs\n",
    "    \n",
    "    x = tf.layers.Dense(100,activation=tf.nn.relu)(inputs)\n",
    "    #x = x.__call__(inputs)\n",
    "    \n",
    "    #yougoujianle quanlianjieceng\n",
    "    x = tf.layers.Dense(100,activation=tf.nn.relu)(x)\n",
    "    \n",
    "    #goujianle yige shuchuceng\n",
    "    #bubaohan softmax ceng de  shenjingwangluo\n",
    "    logits = tf.layers.Dense(10,activation=None)(x)\n",
    "    \n",
    "    return logits\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Graph().as_default() as g:\n",
    "\n",
    "    batch_size = 32\n",
    "    inputs = tf.placeholder(dtype=tf.float32,shape=[None,784])\n",
    "    labels = tf.placeholder(dtype=tf.int32,shape=[None])\n",
    "    \n",
    "    logits = model(inputs)\n",
    "    \n",
    "    #jiaochashang moxing (return jiaochashang)\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        labels=labels,\n",
    "        logits=logits)\n",
    "    \n",
    "    loss = tf.reduce_mean(cross_entropy)\n",
    "    \n",
    "    #dingyi youhuaqi(tidu xiajiang fa)\n",
    "    optim = tf.train.GradientDescentOptimizer(0.001).minimize(loss)\n",
    "\n",
    "    #baocun moxing \n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-d6665331e637>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         _, res_loss = sess.run([optim,loss],feed_dict={\n\u001b[1;32m      7\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_data' is not defined"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g) as sess:\n",
    "    #bianliang chushihua\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(100):\n",
    "        imgs,labs = get_data(...)\n",
    "        _, res_loss = sess.run([optim,loss],feed_dict={\n",
    "            inputs:imgs,\n",
    "            labels:labs\n",
    "        })\n",
    "        print(res_loss)\n",
    "        saver.save(sess, './model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    tf.saved_model.loader.load(sess,['serve'],'/tmp/save_path')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver.save??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_fn(x,y):\n",
    "    r_x = tf.not_equal(x,0)\n",
    "    r_y = y + 1\n",
    "    return r_x,r_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.range(3)\n",
    "labels = tf.zeros(3)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((inputs, labels))\n",
    "dataset = dataset.map(map_fn,4)\n",
    "#dataset = dataset.map(lambda x, y: (tf.not_equal(x, 0), y + 1))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.py_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "(array([[-0.8229255 , -1.3848507 , -2.8479288 ],\n",
      "       [ 0.7130073 , -0.51762736,  2.2607045 ],\n",
      "       [ 0.65415967, -0.4201504 , -1.444615  ]], dtype=float32), array([0, 1, 1], dtype=int32))\n"
     ]
    }
   ],
   "source": [
    "# 制作假数据样本，共5个样本\n",
    "inputs = tf.random_normal([5,3])\n",
    "labels = tf.constant([1,0,1,0,1])\n",
    "\n",
    "# 步骤一：数据读取，生成一个dataset对象\n",
    "dataset = tf.data.Dataset.from_tensor_slices((inputs,labels))\n",
    "\n",
    "# 步骤二：样本处理\n",
    "dataset = dataset.shuffle(2)  # 进行打乱，打乱时cache为2\n",
    "dataset = dataset.batch(3)  # 设置批量大小，这里为3\n",
    "\n",
    "# 步骤三：批量输出\n",
    "iterator = dataset.make_initializable_iterator()  # 生成迭代器对象\n",
    "init_op = iterator.initializer\n",
    "next_batch = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(init_op))\n",
    "    print(sess.run(next_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "(array([[-2.2672563 ,  0.17254902,  1.3951885 ],\n",
      "       [ 0.28764167,  0.24571821,  2.1759105 ],\n",
      "       [-0.5042624 , -0.24933778, -1.4899601 ],\n",
      "       [ 0.6328232 , -1.9907446 , -2.103649  ],\n",
      "       [ 0.81827605,  0.11213845, -1.2033423 ]], dtype=float32), array([0, 0, 1, 1, 1], dtype=int32))\n"
     ]
    }
   ],
   "source": [
    "# 制作假数据样本，共5个样本\n",
    "inputs = tf.random_normal([5,3])\n",
    "labels = tf.constant([1,0,1,0,1])\n",
    "\n",
    "# 步骤一：数据读取，生成一个dataset对象\n",
    "dataset = tf.data.Dataset.from_tensor_slices((inputs,labels))\n",
    "\n",
    "# 步骤二：样本处理\n",
    "dataset = dataset.shuffle(6)  # 进行打乱，打乱时cache为2\n",
    "dataset = dataset.batch(6)  # 设置批量大小，这里为3\n",
    "\n",
    "# 步骤三：批量输出\n",
    "iterator = dataset.make_initializable_iterator()  # 生成迭代器对象\n",
    "init_op = iterator.initializer\n",
    "next_batch = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(init_op))\n",
    "    print(sess.run(next_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.constant([1,2,3,4,5])\n",
    "dataset = tf.data.Dataset.from_tensor_slices(inputs)\n",
    "\n",
    "dataset = dataset.shuffle(buffer_size=3)\n",
    "\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "init_op = iterator.initializer\n",
    "next_batch = iterator.get_next()\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(init_op))\n",
    "    print(sess.run(next_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0]\n",
      " [1 0 0]\n",
      " [2 2 0]\n",
      " [3 3 3]]\n",
      "[[4 4 4 4 0 0 0]\n",
      " [5 5 5 5 5 0 0]\n",
      " [6 6 6 6 6 6 0]\n",
      " [7 7 7 7 7 7 7]]\n",
      "[[ 8  8  8  8  8  8  8  8  0  0  0]\n",
      " [ 9  9  9  9  9  9  9  9  9  0  0]\n",
      " [10 10 10 10 10 10 10 10 10 10  0]\n",
      " [11 11 11 11 11 11 11 11 11 11 11]]\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(100)\n",
    "dataset = dataset.map(lambda x: tf.fill([tf.cast(x, tf.int32)], x))\n",
    "dataset = dataset.padded_batch(4, padded_shapes=[None])\n",
    "\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(next_element))\n",
    "    print(sess.run(next_element))\n",
    "    print(sess.run(next_element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.BytesList()\n",
    "tf.train.Int64List()\n",
    "tf.train.FloatList()\n",
    "\n",
    "tf.train.Feature()\n",
    "\n",
    "tf.train.Features()\n",
    "\n",
    "tf.train.Example()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = tf.data.Dataset.from_tensor_slices(\n",
    "   (tf.random_uniform([4]),\n",
    "    tf.random_uniform([4, 100], maxval=100, dtype=tf.int32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: ((), (100,)), types: (tf.float32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "print(dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
